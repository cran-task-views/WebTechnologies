*Do not edit this README by hand. See [CONTRIBUTING.md](CONTRIBUTING.md).*


This Task View contains information about to use R and the world wide web together. The base version of R does not ship with many tools for interacting with the web. Thankfully, there are an increasingly large number of tools for interacting with the web. This task view focuses on packages for obtaining web-based data and information, frameworks for building web-based R applications, and online services that can be accessed from R. A list of available packages and functions is presented below, grouped by the type of activity. The [rOpenSci Task View: Open Data](https://github.com/ropensci/opendata) provides further discussion of online data sources that can be accessed from R.

If you have any comments or suggestions for additions or improvements for this Task View, go to GitHub and [submit an issue](https://github.com/ropensci/webservices/issues), or make some changes and [submit a pull request](https://github.com/ropensci/webservices/pulls). If you can't contribute on GitHub, [send Scott an email](mailto:myrmecocystus@gmail.com). If you have an issue with one of the packages discussed below, please contact the maintainer of that package.

Tools for Working with the Web from R
-------------------------------------

**Core Tools For HTTP Requests**

There are three main packages that should cover most use cases of interacting with the web from R. <pkg>crul</pkg> is an R6-based HTTP client that provides asynchronous HTTP requests, a pagination helper, HTTP mocking via <pkg>webmockr</pkg>, and request caching for unit tests via <pkg>vcr</pkg>. crul targets R developers more so than end users. <pkg>httr</pkg> provides more of a user facing client for HTTP requests and differentiates from the former package in that it provides support for OAuth. Note that you can pass in additional curl options when you instantiate R6 classes in crul, and the `config` parameter in httr. <pkg>curl</pkg> is a lower-level package that provides a closer interface between R and the [libcurl C library](https://curl.se/libcurl/), but is less user-friendly. curl underlies both crul and httr. curl may be useful for operations on web-based XML or to perform FTP operations (as crul and httr are focused primarily on HTTP). `curl::curl()` is an SSL-compatible replacement for base R's `url()` and has support for http 2.0, SSL (https, ftps), gzip, deflate and more. For websites serving insecure HTTP (i.e. using the "http" not "https" prefix), most R functions can extract data directly, including `read.table` and `read.csv`; this also applies to functions in add-on packages such as `jsonlite::fromJSON()` and `XML::parseXML`. For more specific situations, the following resources may be useful:

-   <pkg>RCurl</pkg> is another low level client for libcurl. Of the two low-level curl clients, we recommend using <pkg>curl</pkg>. <pkg>httpRequest</pkg> is another low-level package for HTTP requests that implements the GET, POST and multipart POST verbs, but we do not recommend its use.
-   <pkg>request</pkg> provides a high-level package that is useful for developing other API client packages. <pkg>httping</pkg> provides simplified tools to ping and time HTTP requests, around <pkg>httr</pkg> calls. <pkg>httpcache</pkg> provides a mechanism for caching HTTP requests.
-   For dynamically generated webpages (i.e., those requiring user interaction to display results), <pkg>RSelenium</pkg> can be used to automate those interactions and extract page contents. It provides a set of bindings for the Selenium 2.0 webdriver using the [JsonWireProtocol](https://github.com/seleniumhq/selenium-google-code-issue-archive). It can also aid in automated application testing, load testing, and web scraping. <pkg>seleniumPipes</pkg> ([GitHub](https://github.com/johndharrison/seleniumPipes)) provides a "pipe"-oriented interface to the same. An alternative to the former two packages is <pkg>splashr</pkg> that vouches to be a lightweight altnernative. <github>cpsievert/rdom</github> (not on CRAN) uses [phantomjs](https://phantomjs.org/) to access a webpage's Document Object Model (DOM).
-   For capturing static content of web pages <pkg>postlightmercury</pkg> is a client for the web service [Mercury](https://mercury.postlight.com/) that turns web pages into structured and clean text.
-   Another, higher-level alternative package useful for webscraping is <pkg>rvest</pkg>, which is designed to work with <pkg>magrittr</pkg> to make it easy to express common web scraping tasks.
-   Many base R tools can be used to download web content, provided that the website does not use SSL (i.e., the URL does not have the "https" prefix). `download.file()` is a general purpose function that can be used to download a remote file. For SSL, the `download()` function in <pkg>downloader</pkg> wraps `download.file()`, and takes all the same arguments.
-   Tabular data sets (e.g., txt, csv, etc.) can be input using `read.table()`, `read.csv()`, and friends, again assuming that the files are not hosted via SSL. An alternative is to use `httr::GET` (or `RCurl::getURL`) to first read the file into R as a character vector before parsing with `read.table(text=...)`, or you can download the file to a local directory. <pkg>rio</pkg> ([GitHub](https://github.com/leeper/rio)) provides an `import()` function that can read a number of common data formats directly from an https:// URL. The <pkg>repmis</pkg> function `source_data()` can load and cache plain-text data from a URL (either http or https). That package also includes `source_Dropbox()` for downloading/caching plain-text data from non-public Dropbox folders and `source_XlsxData()` for downloading/caching Excel xlsx sheets.
-   *Authentication*: Using web resources can require authentication, either via API keys, OAuth, username:password combination, or via other means. Additionally, sometimes web resources that require authentication be in the header of an http call, which requires a little bit of extra work. API keys and username:password combos can be combined within a url for a call to a web resource, or can be specified via commands in <pkg>RCurl</pkg> or <pkg>httr</pkg>. OAuth is the most complicated authentication process, and can be most easily done using <pkg>httr</pkg>. See the 6 demos within <pkg>httr</pkg>, three for OAuth 1.0 (linkedin, twitter, vimeo) and three for OAuth 2.0 (facebook, GitHub, google). <pkg>ROAuth</pkg> is a package that provides a separate R interface to OAuth. OAuth is easier to to do in <pkg>httr</pkg>, so start there. <pkg>googleAuthR</pkg> provides an OAuth 2.0 setup specifically for Google web services, and <pkg>AzureAuth</pkg> provides similar functionality for Azure Active Directory.


**Handling HTTP Errors/Codes**

-   <pkg>fauxpas</pkg> brings a set of Ruby or Python like R6 classes for each individual HTTP status code, allowing simple and verbose messages, with a choice of using messages, warnings, or stops.
-   <pkg>httpcode</pkg> is a simple package to help a user/package find HTTP status codes and associated messages by name or number.


**Parsing Structured Web Data**

The vast majority of web-based data is structured as plain text, HTML, XML, or JSON (javascript object notation). Web service APIs increasingly rely on JSON, but XML is still prevalent in many applications. There are several packages for specifically working with these format. These functions can be used to interact directly with insecure web pages or can be used to parse locally stored or in-memory web files.

-   *XML*: There are two packages for working with XML: <pkg>XML</pkg> and <pkg>xml2</pkg> ([GitHub](https://github.com/r-lib/xml2)). Both support general XML (and HTML) parsing, including XPath queries. The package <pkg>xml2</pkg> is less fully featured, but more user friendly with respect to memory management, classes (e.g., XML node vs. node set vs. document), and namespaces. Of the two, only the <pkg>XML</pkg> supports *de novo* creation of XML nodes and documents. The <pkg>XML2R</pkg> ([GitHub](https://github.com/cpsievert/XML2R)) package is a collection of convenient functions for coercing XML into data frames. An alternative to <pkg>XML</pkg> is [selectr](https://sjp.co.nz/projects/selectr/), which parses CSS3 Selectors and translates them to XPath 1.0 expressions. <pkg>XML</pkg> package is often used for parsing xml and html, but selectr translates CSS selectors to XPath, so can use the CSS selectors instead of XPath.
-   *HTML*: All of the tools that work with XML also work for HTML, though HTML is - in practice - more prone to be malformed. Some tools are designed specifically to work with HTML. `xml2::read_html()` is a good first function to use for importing HTML. <pkg>htmltools</pkg> provides functions to create HTML elements. <pkg>htmltab</pkg> ([GitHub](https://github.com/crubba/htmltab)) extracts structured information from HTML tables, similar to `XML::readHTMLTable` of the <pkg>XML</pkg> package, but automatically expands row and column spans in the header and body cells, and users are given more control over the identification of header and body rows which will end up in the R table. The [selectorgadget browser extension](https://selectorgadget.com/) can be used to identify page elements. <ohat>RHTMLForms</ohat> reads HTML documents and obtains a description of each of the forms it contains, along with the different elements and hidden fields. <pkg>scrapeR</pkg> provides additional tools for scraping data from HTML documents. <pkg>htmltidy</pkg> ([GitHub](https://github.com/hrbrmstr/htmltidy)) provides tools to "tidy" messy HTML documents. <pkg>htm2txt</pkg> uses regex to converts html documents to plain text by removing all html tags. <pkg>Rcrawler</pkg> does crawling and scraping of web pages. 
-   *JSON*: There are several packages for reading and writing JSON: <pkg>rjson</pkg>, <pkg>RJSONIO</pkg>, and <pkg>jsonlite</pkg>. <pkg>jsonlite</pkg> includes a different parser from <pkg>RJSONIO</pkg> called [yajl](https://lloyd.github.io/yajl/). We recommend using <pkg>jsonlite</pkg>. Check out the paper describing jsonlite by Jeroen Ooms <https://arxiv.org/abs/1403.2805>. <pkg>jqr</pkg> provides bindings for the fast JSON library, [jq](http://stedolan.github.io/jq/). <pkg>jsonvalidate</pkg> ([GitHub](https://github.com/ropensci/jsonvalidate)) validates JSON against a schema using the "is-my-json-valid" Javascript library; <pkg>ajv</pkg> does the same using the ajv Javascript library. <pkg>ndjson</pkg> ([GitHub](https://gitlab.com/hrbrmstr/ndjson)) supports the "ndjson" format.
-   *RSS/Atom*: <pkg>feedeR</pkg> can be used to parse RSS or Atom feeds. <pkg>tidyRSS</pkg> parses RSS, Atom XML/JSON and geoRSS into a tidy data.frame.
-   <pkg>swagger</pkg> can be used to automatically generate functions for working with an web service API that provides documentation in [Swagger.io](https://swagger.io/) format.

**Tools for Working with URLs**

-   The `httr::parse_url()` function can be used to extract portions of a URL. The `RCurl::URLencode()` and `utils::URLencode()` functions can be used to encode character strings for use in URLs. `utils::URLdecode()` decodes back to the original strings. <pkg>urltools</pkg> ([GitHub](https://github.com/Ironholds/urltools)) can also handle URL encoding, decoding, parsing, and parameter extraction.
-   <pkg>iptools</pkg> can facilitate working with IPv4 addresses, including for use in geolocation. A similar package <pkg>ipaddress</pkg>, handles IPv4 and IPv6 addresses and networks.
-   <pkg>urlshorteneR</pkg> offers URL expansion and analysis for Bit.ly, Goo.gl, and is.gd. <pkg>longurl</pkg> uses the longurl.org API to provide similar functionality.
-   <pkg>gdns</pkg> provides access to Google's secure HTTP-based DNS resolution service.

**Tools for Working with Scraped Webpage Contents**

-   Several packages can be used for parsing HTML documents. <pkg>boilerpipeR</pkg> provides generic extraction of main text content from HTML files; removal of ads, sidebars and headers using the boilerpipe Java library. <ohat>RTidyHTML</ohat> interfaces to the libtidy library for correcting HTML documents that are not well-formed. This library corrects common errors in HTML documents. <pkg>W3CMarkupValidator</pkg> provides an R Interface to W3C Markup Validation Services for validating HTML documents.
-   For XML documents, the <ohat>XMLSchema</ohat> package provides facilities in R for reading XML schema documents and processing them to create definitions for R classes and functions for converting XML nodes to instances of those classes. It provides the framework for meta-computing with XML schema in R. <pkg>xslt</pkg> is an extension for the <pkg>xml2</pkg> package to transform XML documents by applying an xslt style-sheet. (It can be seen as a modern replacement for <ohat>Sxslt</ohat>, which is an interface to Dan Veillard's libxslt translator, and the <ohat>SXalan</ohat> package.) This may be useful for webscraping, as well as transforming XML markup into another human- or machine-readable format (e.g., HTML, JSON, plain text, etc.). <ohat>SSOAP</ohat> provides a client-side SOAP (Simple Object Access Protocol) mechanism. Beware, SSOAP itself may not install, and/or its dependencies. The best bet is to get the web service maintainers to switch to REST. <ohat>XMLRPC</ohat> provides an implementation of XML-RPC, a relatively simple remote procedure call mechanism that uses HTTP and XML. This can be used for communicating between processes on a single machine or for accessing Web services from within R.
-   <ohat>Rcompression</ohat> (not on CRAN): Interface to zlib and bzip2 libraries for performing in-memory compression and decompression in R. This is useful when receiving or sending contents to remote servers, e.g. Web services, HTTP requests via RCurl.
-   <pkg>tm.plugin.webmining</pkg>: Extensible text retrieval framework for news feeds in XML (RSS, ATOM) and JSON formats. Currently, the following feeds are implemented: Google Blog Search, Google Finance, Google News, NYTimes Article Search, Reuters News Feed, Yahoo Finance and Yahoo Inplay.
-   <pkg>webshot</pkg> uses [PhantomJS](https://phantomjs.org/) to provide screenshots of web pages without a browser. It can be useful for testing websites (such as Shiny applications).

**Security**

- <pkg>securitytxt</pkg> identifies and parses web Security policy files.

**Other Useful Packages and Functions**

-   *Javascript*: <pkg>V8</pkg> is an R interface to Google's open source, high performance JavaScript engine. It can wrap Javascript libraries as well as NPM packages. The <ohat>SpiderMonkey</ohat> package provides another means of evaluating JavaScript code, creating JavaScript objects and calling JavaScript functions and methods from within R. This can work by embedding the JavaScript engine within an R session or by embedding R in an browser such as Firefox and being able to call R from JavaScript and call back to JavaScript from R. The <pkg>js</pkg> package wraps <pkg>V8</pkg> and validates, reformats, optimizes and analyzes JavaScript code.
-   *Email:*: <pkg>mailR</pkg> is an interface to Apache Commons Email to send emails from within R. <pkg>sendmailR</pkg> provides a simple SMTP client. <pkg>gmailr</pkg> provides access the Google's gmail.com RESTful API.
-   *Mocking:*: <pkg>webmockr</pkg> is a library for stubbing and setting expectations on HTTP requests. It is inspired from Rubys `webmock`. This package only helps mock HTTP requests, and returns nothing when requests match expectations. webmockr integrates with the HTTP packages <pkg>crul</pkg> and <pkg>httr</pkg>. See *Testing* for mocking with returned responses.
-   *Testing:*: <pkg>vcr</pkg> provides an interface to easily cache HTTP requests in R package test suites (but can be used outside of testing use cases as well). vcr relies on <pkg>webmockr</pkg> to do the HTTP request mocking. vcr integrates with the HTTP packages <pkg>crul</pkg> and <pkg>httr</pkg>. <pkg>httptest</pkg> provides a framework for testing packages that communicate with HTTP APIs, offering tools for mocking APIs, for recording real API responses for use as mocks, and for making assertions about HTTP requests, all without requiring a live connection to the API server at runtime. httptest only works with httr.
-   *Miscellaneous*: <pkg>webutils</pkg>  contains various functions for developing web applications, including parsers for `application/x-www-form-urlencoded` as well as `multipart/form-data`. <pkg>mime</pkg> ([GitHub](https://github.com/yihui/mime)) guesses the MIME type for a file from its extension. <pkg>rsdmx</pkg> provides tools to read data and metadata documents exchanged through the Statistical Data and Metadata Exchange (SDMX) framework. The package currently focuses on the SDMX XML standard format (SDMX-ML). <pkg>robotstxt</pkg> provides functions and classes for parsing  robots.txt files and checking access permissions; <pkg>spiderbar</pkg> does the same. <pkg>uaparserjs</pkg> ([GitHub](https://github.com/hrbrmstr/uaparserjs)) uses the javascript ["ua-parser" library](https://github.com/ua-parser) to parse User-Agent HTTP headers. <pkg>rapiclient</pkg> is a client for consuming APIs that follow the [Open API format](https://www.openapis.org/). <pkg>restfulr</pkg> models a RESTful service as if it were a nested R list.

Web and Server Frameworks
-------------------------

-   [Model Operationalization](https://docs.microsoft.com/en-us/machine-learning-server/what-is-operationalization) (previously DeployR) is a Microsoft product that provides support for deploying R and Python models and code to a server as a web service to later consume.
-   The <pkg>shiny</pkg> package makes it easy to build interactive web applications with R.
-   <pkg>dash</pkg> is a web framework which is available for Python, R and Julia, with components written in React.js.
-   Other web frameworks include: <pkg>fiery</pkg> that is meant to be more flexible but less easy to use than shiny (<pkg>reqres</pkg> and <pkg>routr</pkg> are utilities used by fiery that provide HTTP request and response classes, and HTTP routing, respectively); <github>att/rcloud</github> provides an iPython notebook-style web-based R interface; and <pkg>Rook</pkg>, which contains the specification and convenience software for building and running Rook applications.
-   The <pkg>opencpu</pkg> framework for embedded statistical computation and reproducible research exposes a web API interfacing R, LaTeX and Pandoc. This API is used for example to integrate statistical functionality into systems, share and execute scripts or reports on centralized servers, and build R based apps.
-   Several general purpose server/client frameworks for R exist. <pkg>Rserve</pkg> and <pkg>RSclient</pkg> provide server and client functionality for TCP/IP or local socket interfaces. <pkg>httpuv</pkg> provides a low-level socket and protocol support for handling HTTP and WebSocket requests directly within R. Another related package, perhaps which <pkg>httpuv</pkg> replaces, is [websockets](https://cran.rstudio.com/src/contrib/Archive/websockets/). <pkg>servr</pkg> provides a simple HTTP server to serve files under a given directory based on httpuv.
-   Several packages offer functionality for turning R code into a web API. <pkg>FastRWeb</pkg> provides some basic infrastructure for this. <pkg>plumber</pkg> allows you to create a REST API by decorating existing R source code.
-   The <ohat>WADL</ohat> package provides tools to process Web Application Description Language (WADL) documents and to programmatically generate R functions to interface to the REST methods described in those WADL documents. (not on CRAN)
-   The <ohat>RDCOMServer</ohat> provides a mechanism to export R objects as (D)COM objects in Windows. It can be used along with the <ohat>RDCOMClient</ohat> package which provides user-level access from R to other COM servers. (not on CRAN)
-   [rapporter.net](http://rapporter.net/welcome/en) provides an online environment (SaaS) to host and run <pkg>rapport</pkg> statistical report templates in the cloud.
-   <pkg>radiant</pkg> ([GitHub](https://github.com/radiant-rstats/radiant)) is Shiny-based GUI for R that runs in a browser from a server or local machine.
-   The [Tiki](https://info.tiki.org/tiki-index.php) Wiki CMS/Groupware framework has an R plugin ([PluginR](https://doc.tiki.org/PluginR)) to run R code from wiki pages, and use data from their own collected web databases (trackers). A demo: <https://r.tiki.org/tiki-index.php>.
-   The [MediaWiki](https://www.mediawiki.org/wiki/MediaWiki) has an extension ([Extension:R](https://www.mediawiki.org/wiki/Extension:R)) to run R code from wiki pages, and use uploaded data. A mailing list used to be available: R-sig-mediawiki.
-   <pkg>whisker</pkg>: Implementation of logicless templating based on [Mustache](http://mustache.github.io/) in R. Mustache syntax is described in <http://mustache.github.io/mustache.5.html>
-   <ohat>CGIwithR</ohat> (not on CRAN) allows one to use R scripts as CGI programs for generating dynamic Web content. HTML forms and other mechanisms to submit dynamic requests can be used to provide input to R scripts via the Web to create content that is determined within that R script.

Web Services
------------

**Cloud Computing and Storage**

-   [The cloudyr project](https://cloudyr.github.io/), which is currently under active development on GitHub, aims to provide interfaces to popular Amazon, Azure and Google cloud services without the need for external system dependencies.
-   Amazon Web Services is a popular, proprietary cloud service offering a suite of computing, storage, and infrastructure tools. <pkg>aws.signature</pkg> provides functionality for generating AWS API request signatures.
      -   *Elastic Cloud Compute (EC2)* is a cloud computing service. <gcode>segue</gcode> (not on CRAN) is a package for managing EC2 instances and S3 storage, which includes a parallel version of `lapply()` for the Elastic Map Reduce (EMR) engine called `emrlapply()`. It uses Hadoop Streaming on Amazon's EMR in order to get simple parallel computation.
      -   *DBREST*: <ohat>RAmazonDBREST</ohat> provides an interface to Amazon's Simple DB API.
      -   <pkg>paws</pkg> ([GitHub](https://github.com/paws-r/paws)) is an interface to nearly all AWS APIs, including compute, storage, databases, and machine learning. It also requires no external system dependencies.
-   Azure is Microsoft's cloud computing service. It provides Paas, SaaS and IaaS and supports many different tools and frameworks, including both Microsoft-specific and third-party systems.
      -   *Azure Active Directory (AAD)* is a centralized directory and identity service. <pkg>AzureAuth</pkg> is an R client for AAD; use this to obtain OAuth tokens for authenticating with other Azure services, including Resource Manager and storage (see next).
      -   *Azure Resource Manager (ARM)* is a service for deploying other Azure services. <pkg>AzureRMR</pkg> is an R interface to ARM, and allows managing subscriptions, resource groups, resources and templates. It exposes a general R6 class framework that can extended to provide extra functionality for specific services (see next).
      -   *Azure Storage Accounts* are a general-purpose data storage facility. Different types of storage are available: file, blob, table, Data Lake, and more. <pkg>AzureStor</pkg> provides an R interface to storage. Features include clients for file, blob and Data Lake Gen2 storage, parallelized file transfers, and an interface to Microsoft's cross-platform AzCopy command line utility. Also supplied is an ARM interface, to allow creation and managing of storage accounts.
      -   *Data Science Virtual Machines (DSVMs)* are Azure VMs that come preloaded with a wide variety of software for statistics and machine learning, including R, Python, TensorFlow, and Spark. <pkg>AzureVM</pkg> is a package for managing DSVMs from within R. It also allows deploying arbitrary VMs by supplying a suitable deployment template.
      -   <pkg>AzureContainers</pkg> provides a unified facility for working with containers in Azure. Specifically, it includes R interfaces to *Azure Container Instances (ACI)*, *Azure Docker Registry (ACR)* and *Azure Kubernetes Service (AKS)*. Create Docker images and push them to an ACR repository; spin up ACI containers; deploy Kubernetes services in AKS.
      -   *Azure Data Explorer*, also known as *Kusto*, is a fast, scalable data exploration and analytics service. <github>cloudyr/AzureKusto</github> (not yet on CRAN) is an R interface to ADE/Kusto. It includes a dplyr client interface similar to that provided by dbplyr for SQL databases, a DBI client interface, and an ARM interface for deploying and managing Kusto clusters and databases.
-   <pkg>googleComputeEngineR</pkg> interacts with the Google Compute Engine API, and lets you create, start and stop instances in the Google Cloud.
-   *Cloud Storage*: <pkg>googleCloudStorageR</pkg> interfaces with Google Cloud Storage. <pkg>boxr</pkg> ([GitHub](https://github.com/r-box/boxr)) is a lightweight, high-level interface for the [box.com API](https://developer.box.com/reference/). <pkg>rdrop2</pkg> is a Dropbox interface that provides access to a full suite of file operations, including dir/copy/move/delete operations, account information (including quotas) and the ability to upload and download files from any Dropbox account.
-   *Docker*: <pkg>analogsea</pkg> is a general purpose client for the Digital Ocean v2 API. In addition, the package includes functions to install various R tools including base R, RStudio server, and more. There's an improving interface to interact with docker on your remote droplets via this package.
-   <pkg>crunch</pkg> [GitHub](https://github.com/Crunch-io/rcrunch) provides an interface to the [crunch.io](https://crunch.io/) storage and analytics platform. <pkg>crunchy</pkg> [GitHub](https://github.com/Crunch-io/crunchy) facilitates making Shiny apps on Crunch.
-   <pkg>rrefine</pkg> provides a client for the [OpenRefine](https://openrefine.org/) (formerly Google Refine) data cleaning service.

**Document and Code Sharing**

-   *Code Sharing*: <pkg>gistr</pkg> ([GitHub](https://github.com/ropensci/gistr)) works with GitHub gists ([gist.github.com](https://gist.github.com/discover)) from R, allowing you to create new gists, update gists with new files, rename files, delete files, get and delete gists, star and un-star gists, fork gists, open a gist in your default browser, get embed code for a gist, list gist commits, and get rate limit information when authenticated. <pkg>git2r</pkg> provides bindings to the git version control system and <pkg>gh</pkg> is a client for the GitHub API. <pkg>gitlabr</pkg> is a [GitLab](https://about.gitlab.com/)-specific client.
-   *Data archiving*: <pkg>dataverse</pkg> ([GitHub](https://github.com/iqss/dataverse-client-r)) provides access to Dataverse 4 APIs. <pkg>rfigshare</pkg> ([GitHub](https://github.com/ropensci/rfigshare)) connects with [Figshare.com](https://figshare.com/). <pkg>dataone</pkg> ([GitHub](https://github.com/DataONEorg/rdataone)) provides a client for [DataONE](https://www.dataone.org/) repositories.
-   *Google Drive/Google Documents*: The <ohat>RGoogleDocs</ohat> package is an example of using the RCurl and XML packages to quickly develop an interface to the Google Documents API. <ohat>RGoogleStorage</ohat> provides programmatic access to the Google Storage API. This allows R users to access and store data on Google's storage. We can upload and download content, create, list and delete folders/buckets, and set access control permissions on objects and buckets.
-   *Google Sheets*: <pkg>googlesheets</pkg> ([GitHub](https://github.com/jennybc/googlesheets)) can access private or public Google Sheets by title, key, or URL. Extract data or edit data. Create, delete, rename, copy, upload, or download spreadsheets and worksheets. <pkg>gsheet</pkg> ([GitHub](https://github.com/maxconway/gsheet)) can download Google Sheets using just the sharing link. Spreadsheets can be downloaded as a data frame, or as plain text to parse manually.
-   <pkg>imguR</pkg> ([GitHub](https://github.com/cloudyr/imguR)) is a package to share plots using the image hosting service [Imgur.com](https://imgur.com/). knitr also has a function `imgur_upload()` to load images from literate programming documents.

**Data Analysis and Processing Services**

-   *Geospatial/Geolocation/Geocoding*: Several packages connect to geolocation/geocoding services. <pkg>rgeolocate</pkg> ([GitHub](https://github.com/ironholds/rgeolocate)) offers several online and offline tools. <github>trestletech/rydn</github> (not on CRAN) is an interface to the Yahoo Developers network geolocation APIs, and <github>hrbrmstr/ipapi</github> can be used to geolocate IPv4/6 addresses and/or domain names using the <http://ip-api.com/> API. <pkg>opencage</pkg> ([GitHub](https://github.com/ropensci/opencage)) provides access to to the [OpenCage](https://opencagedata.com/) geocoding service. <github>hrbrmstr/nominatim</github> (not on CRAN) connects to the [OpenStreetMap Nominatim API](https://github.com/hrbrmstr/nominatim) for reverse geocoding. <github>ropensci/PostcodesioR</github> (not on CRAN) provides post code lookup and geocoding for the United Kingdom. <pkg>geosapi</pkg> is an R client for the [GeoServer](http://geoserver.org/) REST API, an open source implementation used widely for serving spatial data. <pkg>geonapi</pkg> provides an interface to the [GeoNetwork](https://geonetwork-opensource.org/) legacy API, an opensource catalogue for managing geographic metadata. <pkg>ows4R</pkg> is a new R client for the [OGC](https://www.ogc.org/standards/) standard Web-Services, such Web Feature Service (WFS) for data and Catalogue Service (CSW) for metadata.
-   *Machine Learning as a Service*: Several packages provide access to cloud-based machine learning services. <pkg>OpenML</pkg> ([GitHub](https://github.com/openml/openml-r)) is the official client for [the OpenML API](https://www.openml.org/frontend/page/home). <pkg>clarifai</pkg> ([GitHub](https://github.com/soodoku/clarifai)) is a [Clarifai.com](https://www.clarifai.com/) client that enables automated image description. <pkg>rLTP</pkg> ([GitHub](https://github.com/hetong007/rLTP)) accesses the [ltp-cloud service](https://www.ltp-cloud.com/). <pkg>languagelayeR</pkg>  is a client for Languagelayer, a language detection API. [googlepredictionapi](https://code.google.com/archive/p/google-prediction-api-r-client/) (not on CRAN): is an R client for the [Google Prediction API](https://cloud.google.com/ai-platform), a suite of cloud machine learning tools. <pkg>yhatr</pkg> lets you deploy, maintain, and invoke models via the Yhat REST API. <pkg>datarobot</pkg> works with Data Robot's predictive modeling platform. <pkg>mscsweblm4r</pkg> ([GitHub](https://github.com/philferriere/mscsweblm4r)) interfaces with the Microsoft Cognitive Services Web Language Model API and <pkg>mscstexta4r</pkg> ([GitHub](https://github.com/philferriere/mscstexta4r)) uses the Microsoft Cognitive Services Text Analytics REST API. <pkg>rosetteApi</pkg> links to the [Rosette](https://developer.rosette.com/) text analysis API. <pkg>googleLanguageR</pkg> provides interfaces to Google's Cloud Translation API, Natural Language API, Cloud Speech API, and the Cloud Text-to-Speech API.
-   *Machine Translation*: <pkg>translate</pkg> provides bindings for the Google Translate API v2 and <pkg>translateR</pkg> provides bindings for both Google and Microsoft translation APIs. <pkg>RYandexTranslate</pkg> ([GitHub](https://github.com/mukul13/RYandexTranslate)) connects to Yandex Translate. <pkg>transcribeR</pkg> provides automated audio transcription via the HP IDOL service.
-   *Document Processing*: <pkg>abbyyR</pkg> [GitHub](https://github.com/soodoku/abbyyR) and <pkg>captr</pkg> ([GitHub](https://github.com/soodoku/captr)) connect to optical character recognition (OCR) APIs. <pkg>pdftables</pkg> ([GitHub](https://github.com/expersso/pdftables)) uses [the PDFTables.com webservice](https://pdftables.com/) to extract tables from PDFs.
-   *Mapping*: <pkg>osmar</pkg> provides infrastructure to access OpenStreetMap data from different sources to work with the data in common R manner and to convert data into available infrastructure provided by existing R packages (e.g., into sp and igraph objects). <pkg>osrm</pkg> ([GitHub](https://github.com/rCarto/osrm)) provides shortest paths and travel times from OpenStreetMap. <pkg>osmplotr</pkg> ([GitHub](https://github.com/ropensci/osmplotr)) extracts customizable map images from OpenStreetMap. <pkg>RgoogleMaps</pkg> serves two purposes: it provides a comfortable R interface to query the Google server for static maps, and use the map as a background image to overlay plots within R. <ohat>R2GoogleMaps</ohat> provides a mechanism to generate JavaScript code from R that displays data using Google Maps. <ohat>RKMLDevice</ohat> allows to create R graphics in Keyhole Markup Language (KML) format in a manner that allows them to be displayed on Google Earth (or Google Maps), and <ohat>RKML</ohat> provides users with high-level facilities to generate KML. <pkg>plotKML</pkg> can visualization spatial and spatio-temporal objects in Google Earth. <pkg>ggmap</pkg> allows for the easy visualization of spatial data and models on top of Google Maps, OpenStreetMaps, Stamen Maps, or CloudMade Maps using ggplot2. <pkg>mapsapi</pkg> is an sf-compatible interface to Google Maps API. <pkg>leafletR</pkg>: Allows you to display your spatial data on interactive web-maps using the open-source JavaScript library Leaflet. <pkg>openadds</pkg> ([GitHub](https://github.com/sckott/openadds)) is an [Openaddresses](https://openaddresses.io/) client, and <pkg>banR</pkg> provides access to the "Base Adresses Nationale" (BAN) API for French addresses.
-   *Online Surveys*: <pkg>qualtRics</pkg> provide functions to interact with [Qualtrics](https://www.qualtrics.com/). <pkg>WufooR</pkg>  ([GitHub](https://github.com/dmpe/wufoor)) can retrieve data from [Wufoo.com](https://www.wufoo.com/) forms. <pkg>redcapAPI</pkg> ([GitHub](https://github.com/nutterb/redcapAPI)) can provide access to data stored in a REDCap (Research Electronic Data CAPture) database, which is a web application for building and managing online surveys and databases developed at Vanderbilt University. <github>rubenarslan/formr</github> facilitates use of the [formr](https://formr.org/) survey framework, which is built on openCPU. <pkg>Rexperigen</pkg> is a client for the [Experigen experimental platform](https://becker.phonologist.org/experigen/).
-   *Visualization*: Plot.ly is a company that allows you to create visualizations in the web using R (and Python), which is accessible via <pkg>plotly</pkg>. <pkg>googleVis</pkg> provides an interface between R and the Google chart tools. The <ohat>RUbigraph</ohat> package provides an R interface to a Ubigraph server for drawing interactive, dynamic graphs. You can add and remove vertices/nodes and edges in a graph and change their attributes/characteristics such as shape, color, size.
-   *Other*:
    -   <pkg>rrefine</pkg> can import to and export from the [OpenRefine](https://openrefine.org/) data cleaning service.

**Social Media Clients**

-   <pkg>Rfacebook</pkg> provide an interface to the Facebook API.
-   The <ohat>Rflickr</ohat> package provides an interface to the Flickr photo management and sharing application Web service. (not on CRAN)
-   <pkg>instaR</pkg> ([GitHub](https://github.com/pablobarbera/instaR)) is a client for the [Instagram API](https://www.instagram.com/developer/).
-   <pkg>Rlinkedin</pkg> is a client for the LinkedIn API. Auth is via OAuth.
-   <pkg>rpinterest</pkg> connects to the [Pintrest](https://www.pinterest.com/) API.
-   <pkg>vkR</pkg> is a client for VK, a social networking site based in Russia.
-   <github>rladies/meetupr</github> is a client for the Meetup.com API.
-   *Twitter*: <pkg>twitteR</pkg> ([GitHub](https://github.com/geoffjentry/twitteR)) provides an interface to the Twitter web API. It claims to be deprecated in favor of <pkg>rtweet</pkg> ([GitHub](https://github.com/ropensci/rtweet)). <github>gvegayon/twitterreport</github> (not on CRAN) focuses on report generation based on Twitter data. <pkg>streamR</pkg> provides a series of functions that allow users to access Twitter's filter, sample, and user streams, and to parse the output into data frames. OAuth authentication is supported. <pkg>tweet2r</pkg> is an alternative implementation geared toward SQLite and postGIS databases. <pkg>graphTweets</pkg> produces a network graph from a data.frame of tweets.  [tweetscores](https://github.com/pablobarbera/twitter_ideology/tree/master/pkg/tweetscores) (not on CRAN) implements a political ideology scaling measure for specified Twitter users.
- <pkg>brandwatchR</pkg> is a package to retrieve a data from the Brandwatch social listening API. Both raw text and aggregate statistics are available, as well as project and query management functions.

**Web Analytics Services**

-   *Google Trends*: <pkg>gtrendsR</pkg> offers functions to perform and display Google Trends queries.  <ohat>RGoogleTrends</ohat> provides an alternative.
-   *Google Analytics*: <pkg>googleAnalyticsR</pkg>, <pkg>ganalytics</pkg>, and <pkg>RGA</pkg> provide functions for accessing and retrieving data from the [Google Analytics APIs](https://developers.google.com/analytics/). The latter supports OAuth 2.0 authorization. <pkg>RGA</pkg> provides a shiny app to explore data. <pkg>searchConsoleR</pkg> links to the [Google Search Console](https://developers.google.com/webmaster-tools/) (formerly Webmaster Tools).
-   *Online Advertising*: <pkg>fbRads</pkg> can manage Facebook ads via the Facebook Marketing API. <github>WillemPaling/RDoubleClick</github> (not on CRAN) can retrieve data from Google's DoubleClick Campaign Manager Reporting API. <pkg>RSmartlyIO</pkg> ([GitHub](https://github.com/rstats-lab/RSmartlyIO)) loads Facebook and Instagram advertising data provided by [Smartly.io](https://app.smartly.io/).
-   *Other services*: <pkg>RSiteCatalyst</pkg> has functions for accessing the Adobe Analytics (Omniture SiteCatalyst) Reporting API.
-   <pkg>RAdwords</pkg> ([GitHub](https://github.com/jburkhardt/RAdwords)) is a package for loading Google Adwords data.
-   <pkg>webreadr</pkg> ([GitHub](https://github.com/Ironholds/webreadr)) can process various common forms of request log, including the Common and Combined Web Log formats and AWS logs.


**Web Services for R Package Development**

-   R-Hub <http://log.r-hub.io/> is a project to enable package builds across all architectures. <pkg>rhub</pkg> is a package that interfaces with R-Hub to allow you to check a package on the platform.


**Other Web Services**

-   *Push Notifications*: <pkg>RPushbullet</pkg> provides an easy-to-use interface for the Pushbullet service which provides fast and efficient notifications between computers, phones and tablets. <pkg>pushoverr</pkg> ([GitHub](https://github.com/briandconnelly/pushoverr)) can sending push notifications to mobile devices (iOS and Android) and desktop using [Pushover](https://pushover.net/). <pkg>notifyme</pkg> ([GitHub](https://github.com/epijim/notifyme)) can control Phillips Hue lighting.

-   *Reference/bibliography/citation management*: <pkg>rorcid</pkg> ([GitHub](https://github.com/ropensci/rorcid)) is a programmatic interface the [Orcid.org](https://orcid.org/) API, which can be used for identifying scientific authors and their publications (e.g., by DOI). <pkg>rdatacite</pkg> connects to [DataCite](https://datacite.org/), which manages DOIs and metadata for scholarly datasets. <pkg>scholar</pkg> provides functions to extract citation data from Google Scholar.  <pkg>rscopus</pkg> provides functions to extract citation data from Elsevier Scopus APIs. Convenience functions are also provided for comparing multiple scholars and predicting future h-index values. <pkg>mathpix</pkg> convert an image of a formula (typeset or handwritten) via Mathpix webservice to produce the LaTeX code. <pkg>zen4R</pkg> provides an Interface to [Zenodo](https://zenodo.org/) REST API, including management of depositions, attribution of DOIs by 'Zenodo' and upload of files.

-   *Literature*: <pkg>rplos</pkg> is a programmatic interface to the Web Service methods provided by the Public Library of Science journals for search. <pkg>europepmc</pkg> connects to the Europe PubMed Central service. <pkg>pubmed.mineR</pkg> is a package for text mining of [PubMed Abstracts](https://pubmed.ncbi.nlm.nih.gov/) that supports fetching text and XML from PubMed.  <pkg>jstor</pkg> provides functions and helpers to import metadata, ngrams and full-texts from Data for Research service by JSTOR. <pkg>aRxiv</pkg> is a client for the arXiv API, a repository of electronic preprints for computer science, mathematics, physics, quantitative biology, quantitative finance, and statistics. <pkg>roadoi</pkg> provides an interface to the [Unpaywall API](https://unpaywall.org/products/api) for finding free full-text versions of academic papers. <pkg>rcoreoa</pkg> is an interface to the [CORE API](https://core.ac.uk/docs/), a search interface for open access scholarly articles. <pkg>rcrossref</pkg> is an interface to Crossref's API, <pkg>crminer</pkg> extracts full text from scholarly articles retrieved via Crossref's Text and Data Mining service; <pkg>fulltext</pkg> is a general purpose package to search for, retrieve and extract full text from scholarly articles; and <pkg>rromeo</pkg> ([GitHub](https://github.com/ropensci/rromeo)) is an interface to the SHERPA/RoMEO API, a database of scientific journal archival policies regarding pre-, post-print, and accepted manuscript.

-   *Automated Metadata Harvesting*: <pkg>oai</pkg> and <pkg>OAIHarvester</pkg> harvest metadata using the Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH) standard.

-   *Wikipedia*: <pkg>WikipediR</pkg> ([GitHub](https://github.com/Ironholds/WikipediR)) is a wrapper for the MediaWiki API, aimed particularly at the Wikimedia 'production' wikis, such as Wikipedia. <pkg>WikidataR</pkg> ([GitHub](https://github.com/Ironholds/WikidataR)) can request data from [Wikidata.org](https://www.wikidata.org/wiki/Wikidata:Main_Page), the free knowledgebase. <pkg>wikipediatrend</pkg> ([GitHub](https://github.com/petermeissner/wikipediatrend)) provides access to Wikipedia page access statistics. <pkg>WikidataQueryServiceR</pkg> is a client for the [Wikidata Query Service](https://query.wikidata.org/).
-   <pkg>bigrquery</pkg> ([GitHub](https://github.com/r-dbi/bigrquery)): An interface to Google's bigquery.
-   <pkg>discgolf</pkg> ([GitHub](https://github.com/sckott/discgolf)) provides a client to interact with the API for the [Discourse](https://www.discourse.org/) web forum platform. The API is for an installed instance of Discourse, not for the Discourse site itself.
-   <github>stephlocke/mockaRoo</github> (not on CRAN) uses the [MockaRoo API](https://www.mockaroo.com/api/docs) to generate mock or fake data based on an input schema.
-   <pkg>randNames</pkg> ([GitHub](https://github.com/karthik/randNames)) generates random names and personal identifying information using the <https://randomapi.com/> API.
-   <pkg>rerddap</pkg>: A generic R client to interact with any ERDDAP instance, which is a special case of OPeNDAP (<https://en.wikipedia.org/wiki/OPeNDAP>), or *Open-source Project for a Network Data Access Protocol*. Allows user to swap out the base URL to use any ERDDAP instance.
-   <pkg>RStripe</pkg> provides an interface to [Stripe](https://stripe.com/), an online payment processor.
-   <pkg>slackr</pkg> ([GitHub](https://github.com/hrbrmstr/slackr)) is a client for Slack.com messaging platform.
-   <github>dgrtwo/stackr</github> (not on CRAN): An unofficial wrapper for the read-only features of the [Stack Exchange API](https://api.stackexchange.com/).
-   <github>nealrichardson/useRsnap</github> (not on CRAN) provides an interface to the API for [Usersnap](https://www.pivotaltracker.com/), a tool for collecting feedback from web application users.
-   <pkg>duckduckr</pkg> is an R interface [DuckDuckGo's Instant Answer API](https://duckduckgo.com/api)
